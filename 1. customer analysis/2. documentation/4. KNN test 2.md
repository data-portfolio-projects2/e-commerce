## Interpretation of Results

k = 17

![image](https://github.com/user-attachments/assets/9f06c9d9-9a2b-4fc4-97aa-a5f00302b9d2)

**Overall Metrics**

*   **Accuracy:** 89.67%.  High accuracy, but potentially misleading due to imbalanced classes.
*   **Kappa Score:** 0.5951. Moderate agreement beyond chance, but can be improved.
*   **ROC-AUC Score:** 0.8399. Good overall discriminative ability, but varies per class.
*   **No Information Rate (NIR):** 82.22%. Model shows predictive power as accuracy exceeds NIR.

**Class-Wise Performance**

*   **Class 1 (Minority Class):**
    *   **Sensitivity:** 6.67%. Very poor at identifying Class 1.
    *   **Specificity:** 99.93%. Avoids misclassifying other classes as Class 1.
    *   **F1-Score:** 0.118. Poor performance due to low sensitivity.
*   **Class 2:**
    *   **Sensitivity:** 61.7%.  Moderately good at identifying Class 2.
    *   **Specificity:** 99.42%. Strong ability to avoid false positives.
    *   **F1-Score:** 0.690. Moderate performance with reasonable balance.
*   **Class 3 (Dominant Class):**
    *   **Sensitivity:** 100%. Captures all Class 3 instances.
    *   **Specificity:** 55.73%. High false-positive rate due to the class dominance.
    *   **F1-Score:** 0.954. Excellent performance due to high prevalence.
*   **Class 4:**
    *   **Sensitivity:** 13.95%. Poor at identifying Class 4.
    *   **Specificity:** 98.50%. High ability to avoid false positives.
    *   **F1-Score:** 0.203. Poor performance for this class.
*   **Class 5:**
    *   **Sensitivity:** 61.54%.  Moderately good at identifying Class 5.
    *   **Specificity:** 99.78%. Excellent at avoiding false positives.
    *   **F1-Score:** 0.741. Good balance between precision and recall.
*   **Class 6:**
    *   **Sensitivity:** 60%.  Reasonable performance in identifying Class 6.
    *   **Specificity:** 99.78%. High ability to avoid false positives.
    *   **F1-Score:** 0.716. Good predictive performance.

**Key Observations**

*   **Imbalance Challenges:** The model performs well for the majority class (Class 3) but struggles with minority classes (Class 1 and Class 4). This imbalance affects metrics.
*   **Class-Specific Trade-Offs:** High specificity suggests the model is conservative, leading to low sensitivity for minority classes.
*   **Poor Performance for Class 1 and Class 4:** These classes require significant improvement due to low sensitivity and F1-scores.

**Recommendations for Improvement**

*   **Handle Class Imbalance:** Use oversampling (SMOTE) or class-weight adjustments during training.
*   **Feature Selection:** Investigate whether some features bias predictions towards Class 3.
*   **Alternative Models:** Explore ensemble models like Random Forest or XGBoost.
*   **Evaluation Beyond Accuracy:** Focus on metrics like balanced accuracy, precision, recall, and F1-score for each class.
*   **Hyperparameter Tuning:** Optimize k in k-NN to improve sensitivity for minority classes.
