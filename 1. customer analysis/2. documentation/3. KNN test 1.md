# Interpretation of Results: k = 18

![image](https://github.com/user-attachments/assets/5ddaf9b2-1f99-4610-bbbf-573a9e563c9b)

## Confusion Matrix Overview

The confusion matrix highlights the performance of the k-NN model in classifying data across six classes. Each row represents the predicted class, and each column represents the actual class.

## Overall Performance Metrics

*   **Accuracy:** 90.02%
    *   This indicates that 90.02% of the test samples were classified correctly.
*   **95% Confidence Interval (CI):** (88.35%, 91.53%)
    *   This reflects the range of accuracy values we can expect with 95% certainty.
*   **No Information Rate (NIR):** 81.73%
    *   This represents the accuracy of always predicting the majority class. Since the model's accuracy exceeds this, the model is effective.
*   **Kappa:** 0.6296
    *   This suggests moderate agreement between the predictions and the actual values beyond chance.

## Class-wise Metrics

### Class 1:

*   **Sensitivity:** 0% (model failed to detect any instances of Class 1).
*   **Specificity:** 99.79% (high ability to detect non-Class 1 instances).
*   **F1-Score:** NA (due to 0 sensitivity).
*   **Remarks:** The model struggles significantly with this minority class.

### Class 2:

*   **Sensitivity:** 55.36% (moderate detection of Class 2).
*   **Specificity:** 99.34% (excellent detection of non-Class 2).
*   **F1-Score:** 0.6458 (reasonable balance between precision and recall).
*   **Remarks:** The model performs reasonably well for Class 2.

### Class 3:

*   **Sensitivity:** 100% (perfect detection of Class 3).
*   **Specificity:** 61.15% (low ability to distinguish non-Class 3 instances).
*   **F1-Score:** 0.9584 (high accuracy for the majority class).
*   **Remarks:** Class 3 dominates the dataset, which boosts its sensitivity.

### Class 4:

*   **Sensitivity:** 15.48% (poor detection of Class 4).
*   **Specificity:** 99.18% (high detection of non-Class 4).
*   **F1-Score:** 0.2407 (low due to poor sensitivity).
*   **Remarks:** The model struggles with this minority class.

### Class 5:

*   **Sensitivity:** 82.14% (strong detection of Class 5).
*   **Specificity:** 98.76% (excellent ability to detect non-Class 5).
*   **F1-Score:** 0.7731 (good balance between precision and recall).
*   **Remarks:** The model performs well on this class.

### Class 6:

*   **Sensitivity:** 54.90% (moderate detection of Class 6).
*   **Specificity:** 99.93% (excellent at detecting non-Class 6).
*   **F1-Score:** 0.7 (reasonable performance).
*   **Remarks:** Performance is satisfactory, but sensitivity could be improved.

## Additional Metrics

*   **ROC-AUC Score:** 0.8717
    *   This indicates a strong ability of the model to distinguish between classes overall.

## Key Observations

*   **Class Imbalance:**
    *   Class 3 dominates, leading to high sensitivity and F1-scores for this class but poor performance for minority classes like Class 1 and Class 4.
*   **Confusion between Classes:**
    *   Class 3 predictions overlap significantly with Class 2 and Class 4.
    *   Minority classes like Class 1 and Class 4 are underrepresented in predictions.
*   **Need for Improvements:**
    *   Addressing class imbalance (e.g., oversampling minority classes, adjusting decision boundaries).
    *   Enhancing the model's ability to detect minority classes (e.g., tuning k or using weighted distance metrics).

## Conclusion

The model performs well overall, achieving high accuracy and ROC-AUC scores. However, its performance on minority classes needs improvement, as reflected in low sensitivity and F1-scores for Classes 1 and 4. Addressing class imbalance and refining the model may lead to better performance across all classes.
